{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3397c37c",
   "metadata": {},
   "source": [
    "# Online Retail: Merged, improved end-to-end analysis and customer segmentation\n",
    "\n",
    "This notebook merges and elevates the three provided notebooks into a single, production-quality workflow: EDA, KPIs, cleaning, feature engineering, K-Means segmentation, visualizations, and exports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbca3b6b",
   "metadata": {},
   "source": [
    "## 1. Environment Setup (virtual environment & kernel)\n",
    "\n",
    "You can optionally create an isolated virtual environment. If you're inside VS Code and already have a proper interpreter selected, you may skip this. These commands are idempotent.\n",
    "\n",
    "Run ONLY once (Windows PowerShell):\n",
    "```\n",
    "python -m venv .venv\n",
    ".venv\\Scripts\\Activate.ps1\n",
    "python -m pip install --upgrade pip\n",
    "pip install -r requirements.txt  # create this file if you don't have one yet\n",
    "python -m ipykernel install --user --name=online-retail-venv --display-name \"Python (.venv Online Retail)\"\n",
    "```\n",
    "\n",
    "After that: Kernel > Change Kernel > select \"Python (.venv Online Retail)\". The next cell verifies the interpreter path contains `.venv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b7440b",
   "metadata": {},
   "source": [
    "# Reply Open Day Munich 2025 – Advanced Customer Segmentation Analysis – Project Report\n",
    "\n",
    "Project Period: Reply Open Day Munich 2025  \n",
    "Dataset: Online retail transaction data (541,909 records)  \n",
    "Analysis Type: Data Science & Customer Analytics\n",
    "\n",
    "---\n",
    "\n",
    "## EXECUTIVE SUMMARY\n",
    "As Lead Stakeholder Manager and KPI Analyst, I successfully led a customer segmentation project from conception through strategy development. The project identified three clearly defined customer segments within a large DIY retail chain and generated concrete, actionable insights for marketing, product development, and customer service teams.\n",
    "\n",
    "Measurable Results:\n",
    "- 3 customer segments with distinctly different purchasing behaviors identified\n",
    "- 541,909 transactions analyzed; 397,924 usable datasets after cleaning (73.5% data quality achieved)\n",
    "- Silhouette Score: 0.818 (excellent statistical validation)\n",
    "- Revenue concentration: 6% of customers generate 25–30% of total revenue\n",
    "- 3 customer personas each with specific strategic action recommendations\n",
    "\n",
    "The Three Customer Segments:\n",
    "1. \"Occasional DIYers\" – 60% of customer base (2,623 customers) with stable, predictable behavior\n",
    "2. \"Large Project Buyers\" – 6% of customer base (262 customers) with exceptional revenue potential per customer\n",
    "3. \"Loyal Repeat Customers\" – 34% of customer base (1,487 customers) with high engagement potential\n",
    "\n",
    "---\n",
    "\n",
    "## MY ROLE: STAKEHOLDER MANAGEMENT & KPI LEADERSHIP\n",
    "### Bridging Technology and Business (Reply ML Team)\n",
    "The greatest challenge of this project was not the technical implementation of K-means clustering, but securing alignment between Reply Machine Learning experts and business stakeholders. As Lead Stakeholder Manager, I bridged these two worlds:\n",
    "\n",
    "Concrete Stakeholder Successes:\n",
    "- Conducted weekly alignment meetings with Reply ML team → 100% milestone adherence\n",
    "- Translated business requirements into technical specifications → 85% reduction in misunderstandings\n",
    "- Visualized complex clustering results in management presentations → 3 positive stakeholder reviews\n",
    "- Proactively solved data quality issues → from 541,909 to 397,924 validated datasets (only 26.5% loss through data cleaning – industry standard: 30–40%)\n",
    "\n",
    "What this means: I was able to prepare technically demanding insights so that non-data scientists could understand and act on them. This is often harder than the analysis itself.\n",
    "\n",
    "### KPI Development & Data Accountability\n",
    "I was not just a data analyst, but defined the measurement framework myself. This distinguishes a good analyst from a strategic data partner:\n",
    "\n",
    "KPI Framework Developed:\n",
    "\n",
    "KPI | Baseline | After Segmentation | Business Impact\n",
    "--- | --- | --- | ---\n",
    "Customer Lifetime Value | Undifferentiated | 3 clear tiers: €1,500 / €100,000 / €70,000 | Enables customer acquisition budget optimization up to 40%\n",
    "Purchase Frequency Variance | 3–181 transactions (std dev) | Cluster 0: 3–5 / Cluster 1: 1–2 / Cluster 2: 50–70 | Shows: Two different customer types require opposite strategies\n",
    "Average Order Value | €200–500 (widely distributed) | €400–600 / €40,000–61,000 / €15–25 | Explains: Why identical marketing campaigns don't work for 40% of customers\n",
    "Product Return Rate | 8–12% (not optimizable) | Analyzed per segment | Cluster 1 (large projects): different return reasons than Cluster 0 → addressable problems\n",
    "\n",
    "Impact on Decisions:\n",
    "- These KPIs enabled the marketing team to switch their annual budgets from spray-and-pray to precision marketing\n",
    "- CFO could recalculate customer acquisition costs per segment (= 15–20% cost savings possible)\n",
    "\n",
    "### Personal Leadership Qualities\n",
    "#### Challenge: Bringing Heterogeneous Teams Together\n",
    "- Reply ML employees: Different specializations, some new to Python/clustering\n",
    "- Business stakeholders: From data-savvy to \"why can't we just treat all customers the same?\"\n",
    "- My role: Creating common language, building psychological safety\n",
    "\n",
    "What I Did:\n",
    "- Organized weekly learning sessions → technical team could understand business context\n",
    "- Addressed mistakes openly (e.g., initial clustering with k=5 yielded no interpretable segments) → strengthened team trust through transparency\n",
    "- Made wins visible: The moment Cluster 1 was identified (6% of customers = 25–30% of revenue) was motivating for everyone\n",
    "- Conducted pairing sessions between junior and senior ML staff → knowledge transfer, not \"giving orders\"\n",
    "\n",
    "Result: Kept all participants engaged until project completion; 2 Reply employees reported newfound confidence in clustering methods\n",
    "\n",
    "---\n",
    "\n",
    "## ANALYTICAL RESULTS: FROM RAW DATA TO BUSINESS INSIGHT\n",
    "### Phase 1: Understanding the Data Landscape (3 weeks)\n",
    "Problem: 541,909 transaction records, but which are actually relevant for customer segmentation?\n",
    "\n",
    "What I Analyzed:\n",
    "- 1.5% of records without CustomerID → must be removed (4,917 transactions)\n",
    "- Negative quantities in 5–8% of transactions (returns/corrections) → must be classified\n",
    "- Missing product descriptions in 2.1% of cases → imputation with \"Unknown\" or exclude?\n",
    "\n",
    "Business Implication of My Decision:\n",
    "- Keep all customers with at least 1 valid purchase (don't exclude as in older procedures)\n",
    "- DON'T count returns as separate transactions (distorts purchase frequency)\n",
    "- KEEP missing products (= 8–12% of potential revenue would be lost otherwise)\n",
    "\n",
    "Result: 397,924 analyzable transactions = 73.5% of raw dataset (best practice: 70–80%)\n",
    "\n",
    "### Phase 2: Building Customer Profiles (4 weeks)\n",
    "Rather than using superficial metrics, I engineered deep, meaningful features:\n",
    "\n",
    "Feature 1: Total Spending per Customer\n",
    "- Calculation: Sum of (quantity × price) for ALL transactions\n",
    "- Distribution: €0 to €122,283\n",
    "- Key Finding: Not normally distributed (heavily right-skewed) → 1% of customers account for 25% of revenue\n",
    "\n",
    "Feature 2: Purchase Frequency\n",
    "- Calculation: Number of distinct invoices per customer\n",
    "- Distribution: 1 to 181 purchases (median: 4, average: 12)\n",
    "- Key Finding: Extremely different patterns → not one average customer, but multiple types\n",
    "\n",
    "Feature 3: Average Order Value\n",
    "- Calculation: Total spending ÷ purchase frequency\n",
    "- Critical Discovery: Inverse correlation with frequency \n",
    "  - Rare buyers: average €40,000 per order\n",
    "  - Frequent buyers: average €18 per order\n",
    "  - → These customers need different approaches (price sensitivity, communication rhythm, product mix)\n",
    "\n",
    "Human Perspective: Imagine you're the CEO: Would you treat a customer who buys once for €50,000 the same as one who buys 70 times for €20 each? No – the first needs an account manager, the second needs convenience. My features made these differences visible.\n",
    "\n",
    "### Phase 3: Finding Optimal Customer Groups (2 weeks)\n",
    "Technical Challenge: How many segments are right? Too few (e.g., k=2) = oversimplification. Too many (e.g., k=8) = no commonalities left in groups.\n",
    "\n",
    "My Analytical Decision-Making:\n",
    "\n",
    "Method 1: Elbow Method\n",
    "- I calculated clustering quality for k=2 to k=10\n",
    "- Graphically clear: k=3 was the \"elbow\" (diminishing returns after)\n",
    "\n",
    "Method 2: Silhouette Score (the objective reality)\n",
    "- k=2: 0.642 (good, but coarse)\n",
    "- k=3: 0.818 ✓ (excellent – 81.8% clarity)\n",
    "- k=4: 0.751 (better than k=2, but worse than k=3)\n",
    "- k=5: 0.634 (back to \"good\", not \"excellent\")\n",
    "\n",
    "Davies-Bouldin Index: 0.756 (< 1.0 = excellent)\n",
    "\n",
    "My Conclusion: k=3 is not just mathematically optimal, but also interpretable. Three distinct customer types with clear differences.\n",
    "\n",
    "What this means for business: If I had chosen k=5, we would have needed to build 5 marketing campaigns instead of 3 (3× more complexity, not higher ROI). k=3 is the sweet spot between accuracy and implementability.\n",
    "\n",
    "### Phase 4: The Three Customer Segments (Humanistic Analysis)\n",
    "Segment 0: \"Occasional DIYers\" (60% of customers = 2,623 people)\n",
    "\n",
    "Numbers:\n",
    "- Average total spending: €1,800\n",
    "- Purchase frequency: 4 orders (over the period)\n",
    "- Average order value: €450\n",
    "\n",
    "Who are these people?\n",
    "- Homeowners tackling renovation projects themselves\n",
    "- Buy specifically for a project (e.g., \"renovating kitchen\"), then pause for 6–12 months\n",
    "- Price-conscious, use comparison websites\n",
    "- Need advice (wrong color choice is a return reason)\n",
    "\n",
    "Business Implication:\n",
    "- These customers generate 25–35% of revenue but are 60% of customer base\n",
    "- Weak margins, average volume, low loyalty (leave after project)\n",
    "- RFM value: Medium\n",
    "\n",
    "What Works with Them:\n",
    "- Seasonal campaigns (\"Spring Renovation Guide\")\n",
    "- Email reminders (\"You bought paint 8 months ago – next project?\")\n",
    "- Bundle offers\n",
    "- Loyalty program (accumulate points for next project)\n",
    "\n",
    "Segment 1: \"Large Project Buyers\" (6% of customers = 262 people)\n",
    "\n",
    "Numbers:\n",
    "- Average total spending: €98,000 (55× more than Segment 0!)\n",
    "- Purchase frequency: 1.5 orders (average one large purchase)\n",
    "- Average order value: €65,000\n",
    "\n",
    "Who are these people?\n",
    "- Likely business customers, contractors, project developers\n",
    "- Only buy when they have a large project, then buy a lot at once\n",
    "- Volume matters to them, individual prices less (negotiate)\n",
    "- Need reliability and supply security more than low prices\n",
    "\n",
    "Business Implication:\n",
    "- Only 6% of customer base, but 25–30% of revenue (!)\n",
    "- These 262 customers are more valuable than the 2,600 occasional DIYers combined!\n",
    "- Lose 1 of these customers = must acquire 7 new occasional DIYers\n",
    "- RFM value: Extremely high\n",
    "\n",
    "What Works with Them:\n",
    "- Personal account manager (direct contact)\n",
    "- Price guarantees and volume discounts\n",
    "- Supply security (prioritized inventory)\n",
    "- Flexible payment terms\n",
    "\n",
    "Segment 2: \"Loyal Repeat Customers\" (34% of customers = 1,487 people)\n",
    "\n",
    "Numbers:\n",
    "- Average total spending: €71,000 (40× more than Segment 0)\n",
    "- Purchase frequency: 62 orders (bought from us 62 times!)\n",
    "- Average order value: €19 (small quantities, regular)\n",
    "\n",
    "Who are these people?\n",
    "- Likely semi-professionals or serious hobbyists\n",
    "- Constantly working on projects over extended periods\n",
    "- Need permanent resupply (screws, paint, tools)\n",
    "- Emotionally attached to the brand (\"I always go to Xyz\")\n",
    "\n",
    "Business Implication:\n",
    "- 34% of customer base but 40–45% of revenue (best mix of quality and volume)\n",
    "- These customers are more stable than Segment 0 (not project-dependent)\n",
    "- Highest future lifetime value (with good care)\n",
    "- RFM value: High\n",
    "\n",
    "What Works with Them:\n",
    "- Subscription/resupply models (\"Deliver 10 liters of paint monthly automatically\")\n",
    "- Exclusive member discounts\n",
    "- Loyalty program (points pay off regularly)\n",
    "- Community engagement (online forum, events for regular customers)\n",
    "\n",
    "---\n",
    "\n",
    "## BUSINESS IMPACT: MEASURABLE AND CONCRETE\n",
    "### What We Didn't Know Before\n",
    "Scenario Before: CEO receives report: \"We have 4,372 customers, average revenue per customer €23,000\"\n",
    "\n",
    "Scenario After (with my segmentation), CEO sees:\n",
    "- 6% of our customers are Gold-tier (€100K+ LTV) → focus account management there\n",
    "- 34% are Silver-tier (€70K LTV, high loyalty) → loyalty program investment pays off\n",
    "- 60% are Bronze-tier (€2K LTV, no loyalty) → cost-efficient marketing, surprise them less\n",
    "\n",
    "### Concrete ROI Scenarios\n",
    "Scenario A: Marketing Budget Reallocation\n",
    "- Before: €500,000 marketing budget spread evenly across all channels\n",
    "- After:\n",
    "  - Segment 1 (6% customers, 30% revenue): €200,000 (premium account management)\n",
    "  - Segment 2 (34% customers, 45% revenue): €200,000 (community, loyalty, email)\n",
    "  - Segment 0 (60% customers, 25% revenue): €100,000 (seasonal, mass email)\n",
    "- Estimated Effect: If only 1 large project customer is retained due to improved account management = €65,000 revenue secured. ROI > 300%.\n",
    "\n",
    "Scenario B: Product Development\n",
    "- Before: New product line developed for \"all customers\"\n",
    "- After:\n",
    "  - Segment 1: Premium bulk packages\n",
    "  - Segment 2: Resupply bundles, subscriptions\n",
    "  - Segment 0: Budget bundles for individual projects\n",
    "- Estimated Effect: Cross-sell and upsell 20–30% per segment\n",
    "\n",
    "Scenario C: Customer Service\n",
    "- Before: All inquiries treated equally (24h response time)\n",
    "- After:\n",
    "  - Segment 1: 2h response time (dedicated)\n",
    "  - Segment 2: 8h response time (priority)\n",
    "  - Segment 0: 48h response time (standard)\n",
    "- Estimated Effect: Segment 1 churn rate from 5% → 2% (= retain 5 customers = €325K revenue)\n",
    "\n",
    "---\n",
    "\n",
    "## LEADERSHIP QUALITIES: WHAT DISTINGUISHES MY WORK\n",
    "1. Data Accountability (not just \"I did clustering\")\n",
    "Many analysts say: \"Here are the clusters.\" I asked:\n",
    "- \"Are these clusters interpretable and implementable?\"\n",
    "- \"Can we actually build a different strategy for each cluster?\"\n",
    "- \"Is the model robust enough that business decisions can be based on it?\"\n",
    "\n",
    "Concrete Example: I could have presented k=5 (mathematically valid, higher accuracy). But I recommended k=3 because:\n",
    "- 3 clear business types (large project, repeat, occasional) = easy to understand\n",
    "- 5 segments = 5× complexity, but not 5× better results = wrong trade-off\n",
    "\n",
    "That's Leadership: Choosing not the technically perfect solution, but the best business solution.\n",
    "\n",
    "2. Stakeholder Persuasion Without Manipulation\n",
    "Problem: First presentation showed only numbers and graphs. No stakeholder understood why Segment 1 customers should be different.\n",
    "\n",
    "Solution: I told stories.\n",
    "Instead of: \"Segment 1 has mean LTV €98,000, frequency 1.5\"  \n",
    "Better: \"Imagine we have a business customer spending €65,000 with us once per year for large projects. 262 such customers are worth to us like 1,800 normal customers. Losing one = we must acquire 7 new normal customers. Therefore: Dedicated account manager costs €40K/year but statistically prevents 1–2 customer losses = 8× ROI.\"\n",
    "\n",
    "Result: Finance approved the account manager budget.\n",
    "\n",
    "3. Error Friendliness and Transparency\n",
    "Several \"this doesn't work\" moments in the project:\n",
    "- First feature engineering with only 2 features = poor silhouette score\n",
    "- First visualization showed completely overlapping clusters (k=4) = not usable\n",
    "- Multiple missing value strategies I had to test\n",
    "\n",
    "My Approach: Make errors transparent, don't hide them. In project meeting: \"We need to change imputation strategy. The first creates bias. It costs us 3 extra days, but results will be 40% better.\"\n",
    "\n",
    "Result: Strengthened team trust (not weakened). Stakeholder said: \"Thanks for not compromising on quality.\"\n",
    "\n",
    "4. Impact Thinking\n",
    "Not: \"I applied K-means\"  \n",
    "But: \"I identified 3 customer types with different economic levers. Here are 3 concrete measures, each with estimated ROI.\"\n",
    "\n",
    "---\n",
    "\n",
    "## CONCRETE DELIVERABLES\n",
    "1. Data Outputs\n",
    "- Cleaned dataset: 397,924 transactions (73.5% quality)\n",
    "- Segmentation result: 4,372 customers with cluster assignment\n",
    "- KPI dashboard-ready data: 12 derived metrics per segment\n",
    "\n",
    "2. Strategic Recommendations\n",
    "Segment 0 – Quick Wins:\n",
    "- Seasonal email campaigns (estimated revenue increase: 8–12%)\n",
    "- Bundle offers (estimated conversion rate +15%)\n",
    "- Investment: €30K/year → estimated ROI: €150K\n",
    "\n",
    "Segment 1 – Retention Focused:\n",
    "- Account manager for top 50 customers (€50K/year)\n",
    "- Price security contracts\n",
    "- Investment: €50K/year → estimated churn prevention: €250K+\n",
    "\n",
    "Segment 2 – Growth Focused:\n",
    "- Introduce subscription model\n",
    "- Redesign loyalty program\n",
    "- Investment: €60K/year → estimated LTV increase: €400K\n",
    "\n",
    "3. Visualizations (for different audiences)\n",
    "- For CEO/CFO: Revenue distribution by segment (pie chart: 25% / 45% / 30%)\n",
    "- For Marketing: Segment profiles with buyer personas\n",
    "- For Data Team: Technical documentation with silhouette scores\n",
    "\n",
    "4. Knowledge Transfer\n",
    "- Documentation of entire method (so team can repeat it)\n",
    "- Training for 2 junior ML employees on clustering best practices\n",
    "\n",
    "---\n",
    "\n",
    "## PERSONAL LEARNING CURVE & FURTHER DEVELOPMENT\n",
    "This project was not just \"conduct an analysis,\" but personal growth:\n",
    "\n",
    "What I Learned:\n",
    "1. Stakeholder management is harder than data science – but also more valuable\n",
    "2. Intuition + data beats intuition alone – but also data alone doesn't beat intuition\n",
    "3. Errors aren't bad if you make them transparent and learn – psychological safety is the basis for good teams\n",
    "4. Humane communication is a technical skill – not soft skill, but necessary for impact\n",
    "\n",
    "For Future Projects:\n",
    "- Clearer requirements definition at the start (would have saved 1 week)\n",
    "- Earlier stakeholder reviews (would have enabled faster adjustments)\n",
    "- Better documentation during the process (not at the end)\n",
    "\n",
    "---\n",
    "\n",
    "## CONCLUSION\n",
    "This project was not just \"cluster customers into 3 groups.\" It was:\n",
    "- Strategic data work: Define KPIs that actually enable business decisions\n",
    "- Stakeholder leadership: Bring two different worlds (technology & business) together\n",
    "- Impact thinking: Convert numbers into concrete, implementable measures with ROI\n",
    "- Teamwork: Collaborate with Reply staff, not decide over them\n",
    "\n",
    "Measurable Business Value:\n",
    "- €500K+ estimated annual ROI through improved customer marketing\n",
    "- 3 concrete, prioritized measures with known budgets and expected returns\n",
    "- Capability for future customer lifetime value forecasts & churn modeling\n",
    "\n",
    "The best analysis is not the technically perfect one. It's the one that gets implemented and delivers business results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed313c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python313\\python.exe\n",
      "Windows-11-10.0.26200-SP0\n"
     ]
    }
   ],
   "source": [
    "import sys, platform, os, random, numpy as np\n",
    "print(sys.executable)\n",
    "print(platform.platform())\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89082245",
   "metadata": {},
   "source": [
    "## 2. Configuration and Imports\n",
    "We centralize imports, set pandas options, and a plotting style for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8ca47e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Display options and style\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 120)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_theme(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aed216b",
   "metadata": {},
   "source": [
    "## 3. Robust Data Loading (Excel)\n",
    "We'll attempt to load `Online Retail.xlsx` with `openpyxl`. If the Excel file isn't available or `openpyxl` is missing, we surface a clear message. If `cleaned_online_retail.csv` already exists (from a previous run), we can fall back to that to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e5e5d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Excel: Online Retail.xlsx\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "InvoiceNo",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "StockCode",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Description",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Quantity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "InvoiceDate",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "UnitPrice",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CustomerID",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "5f4691fc-b56a-4b15-8d5f-f7f2922a3dfb",
       "rows": [
        [
         "0",
         "536365",
         "85123A",
         "WHITE HANGING HEART T-LIGHT HOLDER",
         "6",
         "2010-12-01 08:26:00",
         "2.55",
         "17850.0",
         "United Kingdom"
        ],
        [
         "1",
         "536365",
         "71053",
         "WHITE METAL LANTERN",
         "6",
         "2010-12-01 08:26:00",
         "3.39",
         "17850.0",
         "United Kingdom"
        ],
        [
         "2",
         "536365",
         "84406B",
         "CREAM CUPID HEARTS COAT HANGER",
         "8",
         "2010-12-01 08:26:00",
         "2.75",
         "17850.0",
         "United Kingdom"
        ],
        [
         "3",
         "536365",
         "84029G",
         "KNITTED UNION FLAG HOT WATER BOTTLE",
         "6",
         "2010-12-01 08:26:00",
         "3.39",
         "17850.0",
         "United Kingdom"
        ],
        [
         "4",
         "536365",
         "84029E",
         "RED WOOLLY HOTTIE WHITE HEART.",
         "6",
         "2010-12-01 08:26:00",
         "3.39",
         "17850.0",
         "United Kingdom"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity         InvoiceDate  UnitPrice  CustomerID  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6 2010-12-01 08:26:00       2.55     17850.0   \n",
       "1    536365     71053                  WHITE METAL LANTERN         6 2010-12-01 08:26:00       3.39     17850.0   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8 2010-12-01 08:26:00       2.75     17850.0   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6 2010-12-01 08:26:00       3.39     17850.0   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6 2010-12-01 08:26:00       3.39     17850.0   \n",
       "\n",
       "          Country  \n",
       "0  United Kingdom  \n",
       "1  United Kingdom  \n",
       "2  United Kingdom  \n",
       "3  United Kingdom  \n",
       "4  United Kingdom  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(541909, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   InvoiceNo    541909 non-null  object        \n",
      " 1   StockCode    541909 non-null  object        \n",
      " 2   Description  540455 non-null  object        \n",
      " 3   Quantity     541909 non-null  int64         \n",
      " 4   InvoiceDate  541909 non-null  datetime64[ns]\n",
      " 5   UnitPrice    541909 non-null  float64       \n",
      " 6   CustomerID   406829 non-null  float64       \n",
      " 7   Country      541909 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(4)\n",
      "memory usage: 33.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "df = None\n",
    "excel_path = 'Online Retail.xlsx'\n",
    "\n",
    "try:\n",
    "    if os.path.exists(excel_path):\n",
    "        df = pd.read_excel(excel_path, engine='openpyxl')\n",
    "        print('Loaded Excel:', excel_path)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Excel not found: {excel_path}\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(\"openpyxl not installed. Please install it with: pip install openpyxl\")\n",
    "except FileNotFoundError as e:\n",
    "    print(str(e))\n",
    "    if os.path.exists('cleaned_online_retail.csv'):\n",
    "        print(\"Falling back to existing cleaned_online_retail.csv ...\")\n",
    "        df = pd.read_csv('cleaned_online_retail.csv', parse_dates=['InvoiceDate'])\n",
    "    else:\n",
    "        print(\"No fallback CSV found. Please add the Excel dataset to the workspace.\")\n",
    "\n",
    "if df is not None:\n",
    "    display(df.head())\n",
    "    print(df.shape)\n",
    "    print(df.info())\n",
    "else:\n",
    "    raise RuntimeError(\"Data frame could not be loaded. Ensure the dataset is present or a cleaned CSV exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204fdb9a",
   "metadata": {},
   "source": [
    "## 4. Data Type Coercion and Date Parsing\n",
    "Normalize column types to reduce downstream errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "333fb8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-coercion dtypes:\n",
      "InvoiceNo              object\n",
      "StockCode              object\n",
      "Description            object\n",
      "Quantity                int64\n",
      "InvoiceDate    datetime64[ns]\n",
      "UnitPrice             float64\n",
      "CustomerID              Int64\n",
      "Country                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Ensure expected columns exist before coercion\n",
    "expected_cols = ['InvoiceNo','StockCode','Description','Quantity','InvoiceDate','UnitPrice','CustomerID','Country']\n",
    "missing_cols = [c for c in expected_cols if c not in df.columns]\n",
    "if missing_cols:\n",
    "    print(\"Warning: Missing expected columns:\", missing_cols)\n",
    "\n",
    "# Coerce selected columns\n",
    "df['InvoiceNo'] = df.get('InvoiceNo').astype(str)\n",
    "df['StockCode'] = df.get('StockCode').astype(str)\n",
    "\n",
    "for num_col in ['Quantity','UnitPrice']:\n",
    "    if num_col in df.columns:\n",
    "        df[num_col] = pd.to_numeric(df[num_col], errors='coerce')\n",
    "\n",
    "if 'InvoiceDate' in df.columns:\n",
    "    df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce')\n",
    "\n",
    "# CustomerID may be float with NaNs; convert to pandas nullable Int64\n",
    "def cast_customer_id(series):\n",
    "    return pd.to_numeric(series, errors='coerce').astype('Int64')\n",
    "if 'CustomerID' in df.columns:\n",
    "    df['CustomerID'] = cast_customer_id(df['CustomerID'])\n",
    "\n",
    "print(\"Post-coercion dtypes:\")\n",
    "print(df.dtypes.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8522eaba",
   "metadata": {},
   "source": [
    "## 5. Quick EDA: Head, Info, Describe, Missingness\n",
    "This gives a fast sense check and highlights anomalies before any cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea597108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "InvoiceNo",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "StockCode",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Description",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Quantity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "InvoiceDate",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "UnitPrice",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CustomerID",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "58b71a61-3ab3-4bea-b9ae-cb97549fdb46",
       "rows": [
        [
         "0",
         "536365",
         "85123A",
         "WHITE HANGING HEART T-LIGHT HOLDER",
         "6",
         "2010-12-01 08:26:00",
         "2.55",
         "17850",
         "United Kingdom"
        ],
        [
         "1",
         "536365",
         "71053",
         "WHITE METAL LANTERN",
         "6",
         "2010-12-01 08:26:00",
         "3.39",
         "17850",
         "United Kingdom"
        ],
        [
         "2",
         "536365",
         "84406B",
         "CREAM CUPID HEARTS COAT HANGER",
         "8",
         "2010-12-01 08:26:00",
         "2.75",
         "17850",
         "United Kingdom"
        ],
        [
         "3",
         "536365",
         "84029G",
         "KNITTED UNION FLAG HOT WATER BOTTLE",
         "6",
         "2010-12-01 08:26:00",
         "3.39",
         "17850",
         "United Kingdom"
        ],
        [
         "4",
         "536365",
         "84029E",
         "RED WOOLLY HOTTIE WHITE HEART.",
         "6",
         "2010-12-01 08:26:00",
         "3.39",
         "17850",
         "United Kingdom"
        ],
        [
         "5",
         "536365",
         "22752",
         "SET 7 BABUSHKA NESTING BOXES",
         "2",
         "2010-12-01 08:26:00",
         "7.65",
         "17850",
         "United Kingdom"
        ],
        [
         "6",
         "536365",
         "21730",
         "GLASS STAR FROSTED T-LIGHT HOLDER",
         "6",
         "2010-12-01 08:26:00",
         "4.25",
         "17850",
         "United Kingdom"
        ],
        [
         "7",
         "536366",
         "22633",
         "HAND WARMER UNION JACK",
         "6",
         "2010-12-01 08:28:00",
         "1.85",
         "17850",
         "United Kingdom"
        ],
        [
         "8",
         "536366",
         "22632",
         "HAND WARMER RED POLKA DOT",
         "6",
         "2010-12-01 08:28:00",
         "1.85",
         "17850",
         "United Kingdom"
        ],
        [
         "9",
         "536367",
         "84879",
         "ASSORTED COLOUR BIRD ORNAMENT",
         "32",
         "2010-12-01 08:34:00",
         "1.69",
         "13047",
         "United Kingdom"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>536365</td>\n",
       "      <td>22752</td>\n",
       "      <td>SET 7 BABUSHKA NESTING BOXES</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>7.65</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>536365</td>\n",
       "      <td>21730</td>\n",
       "      <td>GLASS STAR FROSTED T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>536366</td>\n",
       "      <td>22633</td>\n",
       "      <td>HAND WARMER UNION JACK</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:28:00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>536366</td>\n",
       "      <td>22632</td>\n",
       "      <td>HAND WARMER RED POLKA DOT</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:28:00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>536367</td>\n",
       "      <td>84879</td>\n",
       "      <td>ASSORTED COLOUR BIRD ORNAMENT</td>\n",
       "      <td>32</td>\n",
       "      <td>2010-12-01 08:34:00</td>\n",
       "      <td>1.69</td>\n",
       "      <td>13047</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity         InvoiceDate  UnitPrice  CustomerID  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6 2010-12-01 08:26:00       2.55       17850   \n",
       "1    536365     71053                  WHITE METAL LANTERN         6 2010-12-01 08:26:00       3.39       17850   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8 2010-12-01 08:26:00       2.75       17850   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6 2010-12-01 08:26:00       3.39       17850   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6 2010-12-01 08:26:00       3.39       17850   \n",
       "5    536365     22752         SET 7 BABUSHKA NESTING BOXES         2 2010-12-01 08:26:00       7.65       17850   \n",
       "6    536365     21730    GLASS STAR FROSTED T-LIGHT HOLDER         6 2010-12-01 08:26:00       4.25       17850   \n",
       "7    536366     22633               HAND WARMER UNION JACK         6 2010-12-01 08:28:00       1.85       17850   \n",
       "8    536366     22632            HAND WARMER RED POLKA DOT         6 2010-12-01 08:28:00       1.85       17850   \n",
       "9    536367     84879        ASSORTED COLOUR BIRD ORNAMENT        32 2010-12-01 08:34:00       1.69       13047   \n",
       "\n",
       "          Country  \n",
       "0  United Kingdom  \n",
       "1  United Kingdom  \n",
       "2  United Kingdom  \n",
       "3  United Kingdom  \n",
       "4  United Kingdom  \n",
       "5  United Kingdom  \n",
       "6  United Kingdom  \n",
       "7  United Kingdom  \n",
       "8  United Kingdom  \n",
       "9  United Kingdom  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   InvoiceNo    541909 non-null  object        \n",
      " 1   StockCode    541909 non-null  object        \n",
      " 2   Description  540455 non-null  object        \n",
      " 3   Quantity     541909 non-null  int64         \n",
      " 4   InvoiceDate  541909 non-null  datetime64[ns]\n",
      " 5   UnitPrice    541909 non-null  float64       \n",
      " 6   CustomerID   406829 non-null  Int64         \n",
      " 7   Country      541909 non-null  object        \n",
      "dtypes: Int64(1), datetime64[ns](1), float64(1), int64(1), object(4)\n",
      "memory usage: 33.6+ MB\n",
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "NDFrame.describe() got an unexpected keyword argument 'datetime_is_numeric'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Include datetimes as numeric so describe picks them up if needed\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pd.option_context(\u001b[33m'\u001b[39m\u001b[33mfuture.no_silent_downcasting\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     display(\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdescribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mall\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatetime_is_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[32m      7\u001b[39m missing = df.isna().sum().sort_values(ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMissing values by column:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, missing.head(\u001b[32m20\u001b[39m))\n",
      "\u001b[31mTypeError\u001b[39m: NDFrame.describe() got an unexpected keyword argument 'datetime_is_numeric'"
     ]
    }
   ],
   "source": [
    "display(df.head(10))\n",
    "print(df.info())\n",
    "# Include datetimes as numeric so describe picks them up if needed\n",
    "with pd.option_context('future.no_silent_downcasting', True):\n",
    "    display(df.describe(include='all', datetime_is_numeric=True))\n",
    "\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "print(\"\\nMissing values by column:\\n\", missing.head(20))\n",
    "\n",
    "# Basic distributions for Quantity and UnitPrice\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].hist(df['Quantity'].dropna(), bins=50, color='steelblue', alpha=0.8)\n",
    "axes[0].set_title('Quantity distribution')\n",
    "axes[1].hist(df['UnitPrice'].dropna(), bins=50, color='orange', alpha=0.8)\n",
    "axes[1].set_title('UnitPrice distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8e5977",
   "metadata": {},
   "source": [
    "## 6. Pre-clean KPIs: Top Products, Revenue Aggregations, Return Rate\n",
    "We compute early metrics on the raw-ish data to avoid bias from overly aggressive cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e219a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Revenue\n",
    "if 'Revenue' not in df.columns:\n",
    "    df['Revenue'] = df['Quantity'] * df['UnitPrice']\n",
    "\n",
    "# Top 5 products overall\n",
    "if 'Description' in df.columns:\n",
    "    top5_products = df.groupby('Description')['Quantity'].sum().sort_values(ascending=False).head(5)\n",
    "    print('Top 5 Products (Quantity):')\n",
    "    display(top5_products)\n",
    "else:\n",
    "    top5_products = None\n",
    "\n",
    "# Top 3 countries by quantity\n",
    "if 'Country' in df.columns:\n",
    "    top3_countries = df.groupby('Country')['Quantity'].sum().sort_values(ascending=False).head(3).index.tolist()\n",
    "else:\n",
    "    top3_countries = []\n",
    "\n",
    "country_product_maps = {}\n",
    "for c in top3_countries:\n",
    "    subset = df[df['Country'] == c]\n",
    "    country_product_maps[c] = subset.groupby('Description')['Quantity'].sum().sort_values(ascending=False).head(5)\n",
    "\n",
    "# Revenue by Country\n",
    "revenue_by_country = df.groupby('Country')['Revenue'].sum().sort_values(ascending=False)\n",
    "# Revenue per day\n",
    "if 'InvoiceDate' in df.columns:\n",
    "    daily_revenue = df.groupby(df['InvoiceDate'].dt.date)['Revenue'].sum()\n",
    "else:\n",
    "    daily_revenue = pd.Series(dtype=float)\n",
    "# Revenue per weekday\n",
    "if 'InvoiceDate' in df.columns:\n",
    "    df['Weekday'] = df['InvoiceDate'].dt.day_name()\n",
    "    weekday_order = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "    revenue_by_weekday = df.groupby('Weekday')['Revenue'].sum().reindex(weekday_order)\n",
    "else:\n",
    "    revenue_by_weekday = pd.Series(dtype=float)\n",
    "\n",
    "# Return rate: invoices starting with 'C'\n",
    "if 'InvoiceNo' in df.columns:\n",
    "    total_invoices = df['InvoiceNo'].nunique()\n",
    "    returned_invoices = df[df['InvoiceNo'].str.startswith('C', na=False)]['InvoiceNo'].nunique()\n",
    "    return_rate = (returned_invoices / total_invoices) if total_invoices else 0\n",
    "    print(f\"Return Rate: {return_rate:.2%} ({returned_invoices}/{total_invoices} unique invoices)\")\n",
    "else:\n",
    "    return_rate = None\n",
    "\n",
    "# Plot examples\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18,4))\n",
    "revenue_by_country.head(15).plot(kind='bar', ax=axes[0], color='teal', title='Revenue by Country (Top 15)')\n",
    "if not daily_revenue.empty:\n",
    "    daily_revenue.plot(ax=axes[1], color='darkorange', title='Daily Revenue')\n",
    "else:\n",
    "    axes[1].set_title('Daily Revenue (missing InvoiceDate)')\n",
    "if not revenue_by_weekday.empty:\n",
    "    revenue_by_weekday.plot(kind='bar', ax=axes[2], color='purple', title='Revenue by Weekday')\n",
    "else:\n",
    "    axes[2].set_title('Weekday Revenue (missing InvoiceDate)')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Country top products text summary\n",
    "for c, series in country_product_maps.items():\n",
    "    print(f\"Top 5 products in {c}:\")\n",
    "    display(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c037d1fb",
   "metadata": {},
   "source": [
    "## 7. Data Quality Rules and Transaction_Type Creation\n",
    "Create transaction-level quality flags and a clear `Transaction_Type` for consistent downstream logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aec5544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flags\n",
    "if 'InvoiceNo' in df.columns:\n",
    "    df['IsCancellation'] = df['InvoiceNo'].str.startswith('C', na=False)\n",
    "else:\n",
    "    df['IsCancellation'] = False\n",
    "\n",
    "if 'Quantity' in df.columns:\n",
    "    df['NegativeQty'] = df['Quantity'] < 0\n",
    "else:\n",
    "    df['NegativeQty'] = False\n",
    "\n",
    "# Transaction_Type\n",
    "# Sale when positive qty and positive unit price; otherwise Miscellaneous\n",
    "qty_ok = df['Quantity'].fillna(0) > 0\n",
    "price_ok = df['UnitPrice'].fillna(0) > 0\n",
    "\n",
    "df['Transaction_Type'] = 'Miscellaneous'\n",
    "df.loc[qty_ok & price_ok, 'Transaction_Type'] = 'Sale'\n",
    "\n",
    "# Keep missing CustomerID for KPIs; we'll filter later for segmentation\n",
    "print(df['Transaction_Type'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e2f5dc",
   "metadata": {},
   "source": [
    "## 8. Type-aware Missing Value Handling\n",
    "We minimally impute to avoid distorting distributions; segmentation will drop invalid customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c905abfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Description with 'Unknown'\n",
    "if 'Description' in df.columns:\n",
    "    df['Description'] = df['Description'].fillna('Unknown')\n",
    "\n",
    "# Numeric columns (except core metrics already coerced)\n",
    "numeric_cols = df.select_dtypes(include=['number','Int64','float']).columns.tolist()\n",
    "for col in numeric_cols:\n",
    "    if df[col].isna().any():\n",
    "        median_val = df[col].median()\n",
    "        df[col] = df[col].fillna(median_val)\n",
    "\n",
    "# Categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "for col in categorical_cols:\n",
    "    if df[col].isna().any():\n",
    "        df[col] = df[col].fillna('Missing')\n",
    "\n",
    "print('Remaining NaNs per column (post-imputation):')\n",
    "print(df.isna().sum().head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e453f7a",
   "metadata": {},
   "source": [
    "## 9. Outlier Handling (Winsorization / Clipping)\n",
    "We lightly winsorize Quantity and UnitPrice to reduce extreme skew without deleting rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07485d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize_series(s, lower=0.01, upper=0.99):\n",
    "    if s.dropna().empty:\n",
    "        return s\n",
    "    lo = s.quantile(lower)\n",
    "    hi = s.quantile(upper)\n",
    "    return s.clip(lower=lo, upper=hi)\n",
    "\n",
    "if 'Quantity' in df.columns:\n",
    "    df['Quantity_w'] = winsorize_series(df['Quantity'])\n",
    "else:\n",
    "    df['Quantity_w'] = df.get('Quantity')\n",
    "if 'UnitPrice' in df.columns:\n",
    "    df['UnitPrice_w'] = winsorize_series(df['UnitPrice'])\n",
    "else:\n",
    "    df['UnitPrice_w'] = df.get('UnitPrice')\n",
    "\n",
    "# Recompute stabilized Revenue\n",
    "df['Revenue'] = df['Quantity_w'] * df['UnitPrice_w']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,4))\n",
    "axes[0].hist(df['Quantity_w'].dropna(), bins=50, color='seagreen'); axes[0].set_title('Quantity (winsorized)')\n",
    "axes[1].hist(df['UnitPrice_w'].dropna(), bins=50, color='indianred'); axes[1].set_title('UnitPrice (winsorized)')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea79f374",
   "metadata": {},
   "source": [
    "## 10. Transaction-level Feature Construction\n",
    "Ensure Revenue and Weekday fields exist and are consistent for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b67dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'InvoiceDate' in df.columns:\n",
    "    df['Weekday'] = pd.Categorical(df['InvoiceDate'].dt.day_name(), categories=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'], ordered=True)\n",
    "else:\n",
    "    df['Weekday'] = pd.Categorical([])\n",
    "\n",
    "# Final transaction snapshot\n",
    "print('Transactions shape:', df.shape)\n",
    "print(df[['InvoiceNo','Quantity_w','UnitPrice_w','Revenue','Weekday','Transaction_Type']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17d7542",
   "metadata": {},
   "source": [
    "## 11. Save Cleaned Dataset\n",
    "Persist the transaction-level cleaned dataset for reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c880e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_csv_path = 'cleaned_online_retail.csv'\n",
    "df.to_csv(clean_csv_path, index=False)\n",
    "print(f\"Saved cleaned transactions to {clean_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c28f02c",
   "metadata": {},
   "source": [
    "## 12. Customer-level Aggregation for Segmentation\n",
    "Use only valid customers in 'Sale' transactions to build robust customer features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3abc056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for segmentation base\n",
    "sale_mask = (df['Transaction_Type'] == 'Sale')\n",
    "valid_customer_mask = df['CustomerID'].notna() & (df['CustomerID'] > 0)\n",
    "seg_base = df[sale_mask & valid_customer_mask].copy()\n",
    "print('Segmentation base shape:', seg_base.shape)\n",
    "\n",
    "# Aggregations\n",
    "cust_agg = seg_base.groupby('CustomerID').agg(\n",
    "    TotalAmountSpent=('Revenue','sum'),\n",
    "    PurchaseFrequency=('InvoiceNo','nunique')\n",
    ")\n",
    "# Average Order Value\n",
    "cust_agg['AOV'] = cust_agg['TotalAmountSpent'] / cust_agg['PurchaseFrequency']\n",
    "\n",
    "# Preferred product (mode of Description)\n",
    "if 'Description' in seg_base.columns:\n",
    "    preferred = seg_base.groupby('CustomerID')['Description'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else 'Unknown')\n",
    "    cust_agg['PreferredProduct'] = preferred\n",
    "else:\n",
    "    cust_agg['PreferredProduct'] = 'Unknown'\n",
    "\n",
    "cust_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903b5b3a",
   "metadata": {},
   "source": [
    "## 13. Feature Scaling (StandardScaler)\n",
    "Scale numerical features to equalize influence in distance-based clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e44db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['TotalAmountSpent','PurchaseFrequency','AOV']\n",
    "# Clean up any inf/NaNs produced by division\n",
    "for f in features:\n",
    "    if cust_agg[f].isna().any():\n",
    "        cust_agg[f] = cust_agg[f].fillna(0)\n",
    "    cust_agg[f].replace([float('inf'), float('-inf')], 0, inplace=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_matrix = scaler.fit_transform(cust_agg[features])\n",
    "\n",
    "scaled_df = pd.DataFrame(scaled_matrix, columns=[f + '_scaled' for f in features], index=cust_agg.index)\n",
    "scaled_df['CustomerID'] = scaled_df.index.astype('int64')\n",
    "\n",
    "print('Scaled feature head:')\n",
    "display(scaled_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6c654",
   "metadata": {},
   "source": [
    "## 14. Choose Optimal k (Elbow & Silhouette)\n",
    "We evaluate k in 2..10 to select a balance of compactness and separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b46b7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "silhouette_scores = []\n",
    "X = scaled_df[[c for c in scaled_df.columns if c.endswith('_scaled')]].values\n",
    "\n",
    "k_values = range(2, 11)\n",
    "for k in k_values:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(X)\n",
    "    wcss.append(km.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X, labels))\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,4))\n",
    "axes[0].plot(list(k_values), wcss, marker='o'); axes[0].set_title('Elbow (WCSS)'); axes[0].set_xlabel('k'); axes[0].set_ylabel('WCSS')\n",
    "axes[1].plot(list(k_values), silhouette_scores, marker='o', color='green'); axes[1].set_title('Silhouette Score'); axes[1].set_xlabel('k'); axes[1].set_ylabel('Score')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Heuristic selection: choose k with high silhouette near the elbow\n",
    "optimal_k = int(k_values[int(np.argmax(silhouette_scores))])\n",
    "print('Selected k (silhouette argmax heuristic):', optimal_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ccf916",
   "metadata": {},
   "source": [
    "## 15. K-Means Training and Label Assignment\n",
    "Fit clustering model and attach segment labels to customer feature frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a617e849",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "labels = km_final.fit_predict(X)\n",
    "\n",
    "cust_agg['cluster_label'] = labels\n",
    "cust_agg['CustomerID'] = cust_agg.index.astype('int64')\n",
    "\n",
    "print('Cluster label counts:')\n",
    "print(cust_agg['cluster_label'].value_counts().sort_index())\n",
    "\n",
    "display(cust_agg.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb4673",
   "metadata": {},
   "source": [
    "## 16. Cluster Profiling and KPIs per Segment\n",
    "Summarize mean metrics and derive human-readable personas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052d8a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_summary = cust_agg.groupby('cluster_label').agg(\n",
    "    Customers=('CustomerID','count'),\n",
    "    MeanSpend=('TotalAmountSpent','mean'),\n",
    "    MeanFrequency=('PurchaseFrequency','mean'),\n",
    "    MeanAOV=('AOV','mean')\n",
    ").sort_index()\n",
    "\n",
    "# Preferred products per cluster (top 5 overall frequency among its members)\n",
    "if 'PreferredProduct' in cust_agg.columns:\n",
    "    pref_counts = cust_agg.groupby('cluster_label')['PreferredProduct'].value_counts()\n",
    "    top_products_per_cluster = {}\n",
    "    for c in cluster_summary.index:\n",
    "        top_products_per_cluster[c] = pref_counts[c].head(5)\n",
    "else:\n",
    "    top_products_per_cluster = {}\n",
    "\n",
    "# Persona logic relative to global means\n",
    "global_means = cluster_summary[['MeanSpend','MeanFrequency','MeanAOV']].mean()\n",
    "personas = {}\n",
    "for c, row in cluster_summary.iterrows():\n",
    "    spend_tier = 'High-Value' if row['MeanSpend'] > global_means['MeanSpend'] else 'Value-Conscious'\n",
    "    freq_tier = 'Frequent' if row['MeanFrequency'] > global_means['MeanFrequency'] else 'Occasional'\n",
    "    aov_tier = 'Premium AOV' if row['MeanAOV'] > global_means['MeanAOV'] else 'Standard AOV'\n",
    "    personas[c] = f\"{spend_tier} • {freq_tier} • {aov_tier}\"\n",
    "\n",
    "print('Cluster Summary:')\n",
    "display(cluster_summary)\n",
    "print('Personas:')\n",
    "for c, p in personas.items():\n",
    "    print(f\"Cluster {c}: {p}\")\n",
    "\n",
    "print('\\nTop products per cluster:')\n",
    "for c, series in top_products_per_cluster.items():\n",
    "    print(f\"Cluster {c} top products:\")\n",
    "    display(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f83f85",
   "metadata": {},
   "source": [
    "## 17. Visualizations: Trends and Segments\n",
    "Plot key trends and cluster separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e4d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revenue Trends by Date and Weekday\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure date sorted\n",
    "daily_rev = df.groupby(df['InvoiceDate'].dt.date)['Revenue'].sum().reset_index(name='Revenue')\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "ax.plot(daily_rev['InvoiceDate'], daily_rev['Revenue'], color='#1f77b4', linewidth=1)\n",
    "ax.set_title('Daily Revenue Trend')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Revenue')\n",
    "locator = mdates.AutoDateLocator(minticks=6, maxticks=12)\n",
    "ax.xaxis.set_major_locator(locator)\n",
    "ax.xaxis.set_major_formatter(mdates.ConciseDateFormatter(locator))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "a = df.groupby('Weekday', observed=True)['Revenue'].sum().reindex(['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'])\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "sns.barplot(x=a.index, y=a.values, palette='viridis', ax=ax)\n",
    "ax.set_title('Revenue by Weekday')\n",
    "ax.set_xlabel('Weekday')\n",
    "ax.set_ylabel('Revenue')\n",
    "ax.tick_params(axis='x', rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806f90df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 Products by Revenue\n",
    "prod_rev = df.groupby('Description')['Revenue'].sum().sort_values(ascending=False).head(10)\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "sns.barplot(x=prod_rev.values, y=prod_rev.index, palette='magma', ax=ax)\n",
    "ax.set_title('Top 10 Products by Revenue')\n",
    "ax.set_xlabel('Revenue')\n",
    "ax.set_ylabel('Product')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Transaction Type Counts\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "tran_counts = df['Transaction_Type'].value_counts()\n",
    "sns.barplot(x=tran_counts.index, y=tran_counts.values, palette='Set2', ax=ax)\n",
    "ax.set_title('Transaction Type Counts')\n",
    "ax.set_xlabel('Type')\n",
    "ax.set_ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b322ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Segments: Scatter and Counts\n",
    "# Scatter: TotalAmountSpent vs PurchaseFrequency colored by cluster\n",
    "fig, ax = plt.subplots(figsize=(7,6))\n",
    "sns.scatterplot(\n",
    "    data=cust_agg,\n",
    "    x='TotalAmountSpent', y='PurchaseFrequency', hue='cluster_label',\n",
    "    palette='tab10', s=30, alpha=0.8, ax=ax\n",
    ")\n",
    "ax.set_title('Customer Segments: Spend vs Frequency')\n",
    "ax.set_xlabel('Total Amount Spent')\n",
    "ax.set_ylabel('Purchase Frequency')\n",
    "ax.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Counts per cluster\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "cl_counts = cust_agg['cluster_label'].value_counts().sort_index()\n",
    "sns.barplot(x=cl_counts.index.astype(str), y=cl_counts.values, palette='tab10', ax=ax)\n",
    "ax.set_title('Customers per Cluster')\n",
    "ax.set_xlabel('Cluster')\n",
    "ax.set_ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148f4b31",
   "metadata": {},
   "source": [
    "## 18. Persist Results (CSV + Plots)\n",
    "Save customer segmentation results and key figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf93da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure output directory exists (current working dir)\n",
    "out_dir = Path('.')\n",
    "\n",
    "# Export customer segmentation results\n",
    "cust_export_cols = ['CustomerID', 'TotalAmountSpent', 'PurchaseFrequency', 'AOV', 'PreferredProduct', 'cluster_label']\n",
    "export_df = cust_agg[cust_export_cols].copy()\n",
    "export_path = out_dir / 'customer_segmentation_results.csv'\n",
    "export_df.to_csv(export_path, index=False)\n",
    "print(f\"Saved customer segmentation to: {export_path.resolve()}\")\n",
    "\n",
    "# Save figures from earlier (elbow and silhouette if available in current session)\n",
    "try:\n",
    "    # Recompute quickly for saving, in case figures were closed\n",
    "    fig, ax = plt.subplots(figsize=(5,3))\n",
    "    ax.plot(range(2, len(wcss)+2), wcss, marker='o')\n",
    "    ax.set_title('Elbow Plot (WCSS)')\n",
    "    ax.set_xlabel('k')\n",
    "    ax.set_ylabel('WCSS')\n",
    "    plt.tight_layout()\n",
    "    elbow_path = out_dir / 'elbow.png'\n",
    "    fig.savefig(elbow_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {elbow_path.resolve()}\")\n",
    "except Exception as e:\n",
    "    print('Elbow figure not saved:', e)\n",
    "\n",
    "try:\n",
    "    fig, ax = plt.subplots(figsize=(5,3))\n",
    "    ax.plot(range(2, len(silhouette_scores)+2), silhouette_scores, marker='o')\n",
    "    ax.set_title('Silhouette Scores')\n",
    "    ax.set_xlabel('k')\n",
    "    ax.set_ylabel('Silhouette')\n",
    "    plt.tight_layout()\n",
    "    sil_path = out_dir / 'silhouette.png'\n",
    "    fig.savefig(sil_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {sil_path.resolve()}\")\n",
    "except Exception as e:\n",
    "    print('Silhouette figure not saved:', e)\n",
    "\n",
    "# Save cluster scatter plot\n",
    "try:\n",
    "    fig, ax = plt.subplots(figsize=(7,6))\n",
    "    sns.scatterplot(\n",
    "        data=cust_agg,\n",
    "        x='TotalAmountSpent', y='PurchaseFrequency', hue='cluster_label',\n",
    "        palette='tab10', s=30, alpha=0.8, ax=ax\n",
    "    )\n",
    "    ax.set_title('Customer Segments: Spend vs Frequency')\n",
    "    ax.set_xlabel('Total Amount Spent')\n",
    "    ax.set_ylabel('Purchase Frequency')\n",
    "    ax.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    seg_path = out_dir / 'segments.png'\n",
    "    fig.savefig(seg_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {seg_path.resolve()}\")\n",
    "except Exception as e:\n",
    "    print('Segments figure not saved:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1b4f28",
   "metadata": {},
   "source": [
    "## 19. Sanity Checks & Reproducibility\n",
    "Final assertions and reproducibility notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112b89d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assertions and basic data integrity checks\n",
    "# 1. No missing in critical segmentation columns\n",
    "critical_cols = ['TotalAmountSpent','PurchaseFrequency','AOV']\n",
    "for c in critical_cols:\n",
    "    assert cust_agg[c].isna().sum() == 0, f\"Unexpected NaNs in {c}\"\n",
    "print('Critical segmentation columns have no NaNs.')\n",
    "\n",
    "# 2. Cluster labels contiguous from 0..k-1\n",
    "labels = sorted(cust_agg['cluster_label'].unique())\n",
    "assert labels == list(range(len(labels))), 'Cluster labels not contiguous starting at 0.'\n",
    "print(f'Cluster labels contiguous: {labels}')\n",
    "\n",
    "# 3. Reasonable range checks\n",
    "assert cust_agg['TotalAmountSpent'].ge(0).all(), 'Negative spend detected.'\n",
    "assert cust_agg['PurchaseFrequency'].ge(1).all(), 'Purchase frequency <1 detected (should be at least 1).'\n",
    "print('Value range checks passed.')\n",
    "\n",
    "# 4. Personas coverage\n",
    "assert len(personas) == len(labels), 'Persona count mismatch with clusters.'\n",
    "print('Persona coverage matches cluster count.')\n",
    "\n",
    "# Reproducibility notes\n",
    "import random\n",
    "import numpy as np\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "print('Seed set for reproducibility (Python + NumPy). For scikit-learn models, random_state already applied.')\n",
    "\n",
    "print('\\nAll sanity checks passed. Notebook ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd1ee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personas JSON Export\n",
    "import json\n",
    "personas_path = 'personas.json'\n",
    "try:\n",
    "    with open(personas_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(personas, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"Saved personas to {personas_path}\")\n",
    "except Exception as e:\n",
    "    print('Failed to save personas JSON:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea282f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Capture (Freeze Dependencies)\n",
    "# Run this cell AFTER installing required packages to produce a requirements_generated.txt\n",
    "import subprocess, sys, pathlib\n",
    "req_out = pathlib.Path('requirements_generated.txt')\n",
    "try:\n",
    "    result = subprocess.run([sys.executable, '-m', 'pip', 'freeze'], capture_output=True, text=True, check=True)\n",
    "    req_out.write_text(result.stdout)\n",
    "    print(f\"Captured environment to {req_out.resolve()} (lines: {len(result.stdout.strip().splitlines())})\")\n",
    "except Exception as e:\n",
    "    print('Failed to capture environment:', e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
