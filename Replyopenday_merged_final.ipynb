{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3397c37c",
   "metadata": {},
   "source": [
    "# Online Retail: Merged, improved end-to-end analysis and customer segmentation\n",
    "\n",
    "This notebook merges and elevates the three provided notebooks into a single, production-quality workflow: EDA, KPIs, cleaning, feature engineering, K-Means segmentation, visualizations, and exports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbca3b6b",
   "metadata": {},
   "source": [
    "## 1. Environment Setup (virtual environment & kernel)\n",
    "\n",
    "You can optionally create an isolated virtual environment. If you're inside VS Code and already have a proper interpreter selected, you may skip this. These commands are idempotent.\n",
    "\n",
    "Run ONLY once (Windows PowerShell):\n",
    "```\n",
    "python -m venv .venv\n",
    ".venv\\Scripts\\Activate.ps1\n",
    "python -m pip install --upgrade pip\n",
    "pip install -r requirements.txt  # create this file if you don't have one yet\n",
    "python -m ipykernel install --user --name=online-retail-venv --display-name \"Python (.venv Online Retail)\"\n",
    "```\n",
    "\n",
    "After that: Kernel > Change Kernel > select \"Python (.venv Online Retail)\". The next cell verifies the interpreter path contains `.venv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed313c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python313\\python.exe\n",
      "Windows-11-10.0.26200-SP0\n"
     ]
    }
   ],
   "source": [
    "import sys, platform, os, random, numpy as np\n",
    "print(sys.executable)\n",
    "print(platform.platform())\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89082245",
   "metadata": {},
   "source": [
    "## 2. Configuration and Imports\n",
    "We centralize imports, set pandas options, and a plotting style for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8ca47e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Display options and style\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 120)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_theme(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aed216b",
   "metadata": {},
   "source": [
    "## 3. Robust Data Loading (Excel)\n",
    "We'll attempt to load `Online Retail.xlsx` with `openpyxl`. If the Excel file isn't available or `openpyxl` is missing, we surface a clear message. If `cleaned_online_retail.csv` already exists (from a previous run), we can fall back to that to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5e5d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "df = None\n",
    "excel_path = 'Online Retail.xlsx'\n",
    "\n",
    "try:\n",
    "    if os.path.exists(excel_path):\n",
    "        df = pd.read_excel(excel_path, engine='openpyxl')\n",
    "        print('Loaded Excel:', excel_path)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Excel not found: {excel_path}\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(\"openpyxl not installed. Please install it with: pip install openpyxl\")\n",
    "except FileNotFoundError as e:\n",
    "    print(str(e))\n",
    "    if os.path.exists('cleaned_online_retail.csv'):\n",
    "        print(\"Falling back to existing cleaned_online_retail.csv ...\")\n",
    "        df = pd.read_csv('cleaned_online_retail.csv', parse_dates=['InvoiceDate'])\n",
    "    else:\n",
    "        print(\"No fallback CSV found. Please add the Excel dataset to the workspace.\")\n",
    "\n",
    "if df is not None:\n",
    "    display(df.head())\n",
    "    print(df.shape)\n",
    "    print(df.info())\n",
    "else:\n",
    "    raise RuntimeError(\"Data frame could not be loaded. Ensure the dataset is present or a cleaned CSV exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204fdb9a",
   "metadata": {},
   "source": [
    "## 4. Data Type Coercion and Date Parsing\n",
    "Normalize column types to reduce downstream errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333fb8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-coercion dtypes:\n",
      "InvoiceNo              object\n",
      "StockCode              object\n",
      "Description            object\n",
      "Quantity                int64\n",
      "InvoiceDate    datetime64[ns]\n",
      "UnitPrice             float64\n",
      "CustomerID              Int64\n",
      "Country                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Ensure expected columns exist before coercion\n",
    "expected_cols = ['InvoiceNo','StockCode','Description','Quantity','InvoiceDate','UnitPrice','CustomerID','Country']\n",
    "missing_cols = [c for c in expected_cols if c not in df.columns]\n",
    "if missing_cols:\n",
    "    print(\"Warning: Missing expected columns:\", missing_cols)\n",
    "\n",
    "# Coerce selected columns\n",
    "df['InvoiceNo'] = df.get('InvoiceNo').astype(str)\n",
    "df['StockCode'] = df.get('StockCode').astype(str)\n",
    "\n",
    "for num_col in ['Quantity','UnitPrice']:\n",
    "    if num_col in df.columns:\n",
    "        df[num_col] = pd.to_numeric(df[num_col], errors='coerce')\n",
    "\n",
    "if 'InvoiceDate' in df.columns:\n",
    "    df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce')\n",
    "\n",
    "# CustomerID may be float with NaNs; convert to pandas nullable Int64\n",
    "def cast_customer_id(series):\n",
    "    return pd.to_numeric(series, errors='coerce').astype('Int64')\n",
    "if 'CustomerID' in df.columns:\n",
    "    df['CustomerID'] = cast_customer_id(df['CustomerID'])\n",
    "\n",
    "print(\"Post-coercion dtypes:\")\n",
    "print(df.dtypes.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8522eaba",
   "metadata": {},
   "source": [
    "## 5. Quick EDA: Head, Info, Describe, Missingness\n",
    "This gives a fast sense check and highlights anomalies before any cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea597108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "InvoiceNo",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "StockCode",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Description",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Quantity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "InvoiceDate",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "UnitPrice",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CustomerID",
         "rawType": "Int64",
         "type": "integer"
        },
        {
         "name": "Country",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "58b71a61-3ab3-4bea-b9ae-cb97549fdb46",
       "rows": [
        [
         "0",
         "536365",
         "85123A",
         "WHITE HANGING HEART T-LIGHT HOLDER",
         "6",
         "2010-12-01 08:26:00",
         "2.55",
         "17850",
         "United Kingdom"
        ],
        [
         "1",
         "536365",
         "71053",
         "WHITE METAL LANTERN",
         "6",
         "2010-12-01 08:26:00",
         "3.39",
         "17850",
         "United Kingdom"
        ],
        [
         "2",
         "536365",
         "84406B",
         "CREAM CUPID HEARTS COAT HANGER",
         "8",
         "2010-12-01 08:26:00",
         "2.75",
         "17850",
         "United Kingdom"
        ],
        [
         "3",
         "536365",
         "84029G",
         "KNITTED UNION FLAG HOT WATER BOTTLE",
         "6",
         "2010-12-01 08:26:00",
         "3.39",
         "17850",
         "United Kingdom"
        ],
        [
         "4",
         "536365",
         "84029E",
         "RED WOOLLY HOTTIE WHITE HEART.",
         "6",
         "2010-12-01 08:26:00",
         "3.39",
         "17850",
         "United Kingdom"
        ],
        [
         "5",
         "536365",
         "22752",
         "SET 7 BABUSHKA NESTING BOXES",
         "2",
         "2010-12-01 08:26:00",
         "7.65",
         "17850",
         "United Kingdom"
        ],
        [
         "6",
         "536365",
         "21730",
         "GLASS STAR FROSTED T-LIGHT HOLDER",
         "6",
         "2010-12-01 08:26:00",
         "4.25",
         "17850",
         "United Kingdom"
        ],
        [
         "7",
         "536366",
         "22633",
         "HAND WARMER UNION JACK",
         "6",
         "2010-12-01 08:28:00",
         "1.85",
         "17850",
         "United Kingdom"
        ],
        [
         "8",
         "536366",
         "22632",
         "HAND WARMER RED POLKA DOT",
         "6",
         "2010-12-01 08:28:00",
         "1.85",
         "17850",
         "United Kingdom"
        ],
        [
         "9",
         "536367",
         "84879",
         "ASSORTED COLOUR BIRD ORNAMENT",
         "32",
         "2010-12-01 08:34:00",
         "1.69",
         "13047",
         "United Kingdom"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>536365</td>\n",
       "      <td>22752</td>\n",
       "      <td>SET 7 BABUSHKA NESTING BOXES</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>7.65</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>536365</td>\n",
       "      <td>21730</td>\n",
       "      <td>GLASS STAR FROSTED T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:26:00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>536366</td>\n",
       "      <td>22633</td>\n",
       "      <td>HAND WARMER UNION JACK</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:28:00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>536366</td>\n",
       "      <td>22632</td>\n",
       "      <td>HAND WARMER RED POLKA DOT</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-12-01 08:28:00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>17850</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>536367</td>\n",
       "      <td>84879</td>\n",
       "      <td>ASSORTED COLOUR BIRD ORNAMENT</td>\n",
       "      <td>32</td>\n",
       "      <td>2010-12-01 08:34:00</td>\n",
       "      <td>1.69</td>\n",
       "      <td>13047</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity         InvoiceDate  UnitPrice  CustomerID  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6 2010-12-01 08:26:00       2.55       17850   \n",
       "1    536365     71053                  WHITE METAL LANTERN         6 2010-12-01 08:26:00       3.39       17850   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8 2010-12-01 08:26:00       2.75       17850   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6 2010-12-01 08:26:00       3.39       17850   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6 2010-12-01 08:26:00       3.39       17850   \n",
       "5    536365     22752         SET 7 BABUSHKA NESTING BOXES         2 2010-12-01 08:26:00       7.65       17850   \n",
       "6    536365     21730    GLASS STAR FROSTED T-LIGHT HOLDER         6 2010-12-01 08:26:00       4.25       17850   \n",
       "7    536366     22633               HAND WARMER UNION JACK         6 2010-12-01 08:28:00       1.85       17850   \n",
       "8    536366     22632            HAND WARMER RED POLKA DOT         6 2010-12-01 08:28:00       1.85       17850   \n",
       "9    536367     84879        ASSORTED COLOUR BIRD ORNAMENT        32 2010-12-01 08:34:00       1.69       13047   \n",
       "\n",
       "          Country  \n",
       "0  United Kingdom  \n",
       "1  United Kingdom  \n",
       "2  United Kingdom  \n",
       "3  United Kingdom  \n",
       "4  United Kingdom  \n",
       "5  United Kingdom  \n",
       "6  United Kingdom  \n",
       "7  United Kingdom  \n",
       "8  United Kingdom  \n",
       "9  United Kingdom  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541909 entries, 0 to 541908\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   InvoiceNo    541909 non-null  object        \n",
      " 1   StockCode    541909 non-null  object        \n",
      " 2   Description  540455 non-null  object        \n",
      " 3   Quantity     541909 non-null  int64         \n",
      " 4   InvoiceDate  541909 non-null  datetime64[ns]\n",
      " 5   UnitPrice    541909 non-null  float64       \n",
      " 6   CustomerID   406829 non-null  Int64         \n",
      " 7   Country      541909 non-null  object        \n",
      "dtypes: Int64(1), datetime64[ns](1), float64(1), int64(1), object(4)\n",
      "memory usage: 33.6+ MB\n",
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "NDFrame.describe() got an unexpected keyword argument 'datetime_is_numeric'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Include datetimes as numeric so describe picks them up if needed\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pd.option_context(\u001b[33m'\u001b[39m\u001b[33mfuture.no_silent_downcasting\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     display(\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdescribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mall\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatetime_is_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[32m      7\u001b[39m missing = df.isna().sum().sort_values(ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMissing values by column:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m, missing.head(\u001b[32m20\u001b[39m))\n",
      "\u001b[31mTypeError\u001b[39m: NDFrame.describe() got an unexpected keyword argument 'datetime_is_numeric'"
     ]
    }
   ],
   "source": [
    "display(df.head(10))\n",
    "print(df.info())\n",
    "# Include datetimes as numeric so describe picks them up if needed\n",
    "with pd.option_context('future.no_silent_downcasting', True):\n",
    "    display(df.describe(include='all', datetime_is_numeric=True))\n",
    "\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "print(\"\\nMissing values by column:\\n\", missing.head(20))\n",
    "\n",
    "# Basic distributions for Quantity and UnitPrice\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].hist(df['Quantity'].dropna(), bins=50, color='steelblue', alpha=0.8)\n",
    "axes[0].set_title('Quantity distribution')\n",
    "axes[1].hist(df['UnitPrice'].dropna(), bins=50, color='orange', alpha=0.8)\n",
    "axes[1].set_title('UnitPrice distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8e5977",
   "metadata": {},
   "source": [
    "## 6. Pre-clean KPIs: Top Products, Revenue Aggregations, Return Rate\n",
    "We compute early metrics on the raw-ish data to avoid bias from overly aggressive cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e219a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Revenue\n",
    "if 'Revenue' not in df.columns:\n",
    "    df['Revenue'] = df['Quantity'] * df['UnitPrice']\n",
    "\n",
    "# Top 5 products overall\n",
    "if 'Description' in df.columns:\n",
    "    top5_products = df.groupby('Description')['Quantity'].sum().sort_values(ascending=False).head(5)\n",
    "    print('Top 5 Products (Quantity):')\n",
    "    display(top5_products)\n",
    "else:\n",
    "    top5_products = None\n",
    "\n",
    "# Top 3 countries by quantity\n",
    "if 'Country' in df.columns:\n",
    "    top3_countries = df.groupby('Country')['Quantity'].sum().sort_values(ascending=False).head(3).index.tolist()\n",
    "else:\n",
    "    top3_countries = []\n",
    "\n",
    "country_product_maps = {}\n",
    "for c in top3_countries:\n",
    "    subset = df[df['Country'] == c]\n",
    "    country_product_maps[c] = subset.groupby('Description')['Quantity'].sum().sort_values(ascending=False).head(5)\n",
    "\n",
    "# Revenue by Country\n",
    "revenue_by_country = df.groupby('Country')['Revenue'].sum().sort_values(ascending=False)\n",
    "# Revenue per day\n",
    "if 'InvoiceDate' in df.columns:\n",
    "    daily_revenue = df.groupby(df['InvoiceDate'].dt.date)['Revenue'].sum()\n",
    "else:\n",
    "    daily_revenue = pd.Series(dtype=float)\n",
    "# Revenue per weekday\n",
    "if 'InvoiceDate' in df.columns:\n",
    "    df['Weekday'] = df['InvoiceDate'].dt.day_name()\n",
    "    weekday_order = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "    revenue_by_weekday = df.groupby('Weekday')['Revenue'].sum().reindex(weekday_order)\n",
    "else:\n",
    "    revenue_by_weekday = pd.Series(dtype=float)\n",
    "\n",
    "# Return rate: invoices starting with 'C'\n",
    "if 'InvoiceNo' in df.columns:\n",
    "    total_invoices = df['InvoiceNo'].nunique()\n",
    "    returned_invoices = df[df['InvoiceNo'].str.startswith('C', na=False)]['InvoiceNo'].nunique()\n",
    "    return_rate = (returned_invoices / total_invoices) if total_invoices else 0\n",
    "    print(f\"Return Rate: {return_rate:.2%} ({returned_invoices}/{total_invoices} unique invoices)\")\n",
    "else:\n",
    "    return_rate = None\n",
    "\n",
    "# Plot examples\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18,4))\n",
    "revenue_by_country.head(15).plot(kind='bar', ax=axes[0], color='teal', title='Revenue by Country (Top 15)')\n",
    "if not daily_revenue.empty:\n",
    "    daily_revenue.plot(ax=axes[1], color='darkorange', title='Daily Revenue')\n",
    "else:\n",
    "    axes[1].set_title('Daily Revenue (missing InvoiceDate)')\n",
    "if not revenue_by_weekday.empty:\n",
    "    revenue_by_weekday.plot(kind='bar', ax=axes[2], color='purple', title='Revenue by Weekday')\n",
    "else:\n",
    "    axes[2].set_title('Weekday Revenue (missing InvoiceDate)')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Country top products text summary\n",
    "for c, series in country_product_maps.items():\n",
    "    print(f\"Top 5 products in {c}:\")\n",
    "    display(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c037d1fb",
   "metadata": {},
   "source": [
    "## 7. Data Quality Rules and Transaction_Type Creation\n",
    "Create transaction-level quality flags and a clear `Transaction_Type` for consistent downstream logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aec5544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flags\n",
    "if 'InvoiceNo' in df.columns:\n",
    "    df['IsCancellation'] = df['InvoiceNo'].str.startswith('C', na=False)\n",
    "else:\n",
    "    df['IsCancellation'] = False\n",
    "\n",
    "if 'Quantity' in df.columns:\n",
    "    df['NegativeQty'] = df['Quantity'] < 0\n",
    "else:\n",
    "    df['NegativeQty'] = False\n",
    "\n",
    "# Transaction_Type\n",
    "# Sale when positive qty and positive unit price; otherwise Miscellaneous\n",
    "qty_ok = df['Quantity'].fillna(0) > 0\n",
    "price_ok = df['UnitPrice'].fillna(0) > 0\n",
    "\n",
    "df['Transaction_Type'] = 'Miscellaneous'\n",
    "df.loc[qty_ok & price_ok, 'Transaction_Type'] = 'Sale'\n",
    "\n",
    "# Keep missing CustomerID for KPIs; we'll filter later for segmentation\n",
    "print(df['Transaction_Type'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e2f5dc",
   "metadata": {},
   "source": [
    "## 8. Type-aware Missing Value Handling\n",
    "We minimally impute to avoid distorting distributions; segmentation will drop invalid customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c905abfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Description with 'Unknown'\n",
    "if 'Description' in df.columns:\n",
    "    df['Description'] = df['Description'].fillna('Unknown')\n",
    "\n",
    "# Numeric columns (except core metrics already coerced)\n",
    "numeric_cols = df.select_dtypes(include=['number','Int64','float']).columns.tolist()\n",
    "for col in numeric_cols:\n",
    "    if df[col].isna().any():\n",
    "        median_val = df[col].median()\n",
    "        df[col] = df[col].fillna(median_val)\n",
    "\n",
    "# Categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "for col in categorical_cols:\n",
    "    if df[col].isna().any():\n",
    "        df[col] = df[col].fillna('Missing')\n",
    "\n",
    "print('Remaining NaNs per column (post-imputation):')\n",
    "print(df.isna().sum().head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e453f7a",
   "metadata": {},
   "source": [
    "## 9. Outlier Handling (Winsorization / Clipping)\n",
    "We lightly winsorize Quantity and UnitPrice to reduce extreme skew without deleting rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07485d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize_series(s, lower=0.01, upper=0.99):\n",
    "    if s.dropna().empty:\n",
    "        return s\n",
    "    lo = s.quantile(lower)\n",
    "    hi = s.quantile(upper)\n",
    "    return s.clip(lower=lo, upper=hi)\n",
    "\n",
    "if 'Quantity' in df.columns:\n",
    "    df['Quantity_w'] = winsorize_series(df['Quantity'])\n",
    "else:\n",
    "    df['Quantity_w'] = df.get('Quantity')\n",
    "if 'UnitPrice' in df.columns:\n",
    "    df['UnitPrice_w'] = winsorize_series(df['UnitPrice'])\n",
    "else:\n",
    "    df['UnitPrice_w'] = df.get('UnitPrice')\n",
    "\n",
    "# Recompute stabilized Revenue\n",
    "df['Revenue'] = df['Quantity_w'] * df['UnitPrice_w']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,4))\n",
    "axes[0].hist(df['Quantity_w'].dropna(), bins=50, color='seagreen'); axes[0].set_title('Quantity (winsorized)')\n",
    "axes[1].hist(df['UnitPrice_w'].dropna(), bins=50, color='indianred'); axes[1].set_title('UnitPrice (winsorized)')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea79f374",
   "metadata": {},
   "source": [
    "## 10. Transaction-level Feature Construction\n",
    "Ensure Revenue and Weekday fields exist and are consistent for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b67dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'InvoiceDate' in df.columns:\n",
    "    df['Weekday'] = pd.Categorical(df['InvoiceDate'].dt.day_name(), categories=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'], ordered=True)\n",
    "else:\n",
    "    df['Weekday'] = pd.Categorical([])\n",
    "\n",
    "# Final transaction snapshot\n",
    "print('Transactions shape:', df.shape)\n",
    "print(df[['InvoiceNo','Quantity_w','UnitPrice_w','Revenue','Weekday','Transaction_Type']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17d7542",
   "metadata": {},
   "source": [
    "## 11. Save Cleaned Dataset\n",
    "Persist the transaction-level cleaned dataset for reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c880e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_csv_path = 'cleaned_online_retail.csv'\n",
    "df.to_csv(clean_csv_path, index=False)\n",
    "print(f\"Saved cleaned transactions to {clean_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c28f02c",
   "metadata": {},
   "source": [
    "## 12. Customer-level Aggregation for Segmentation\n",
    "Use only valid customers in 'Sale' transactions to build robust customer features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3abc056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for segmentation base\n",
    "sale_mask = (df['Transaction_Type'] == 'Sale')\n",
    "valid_customer_mask = df['CustomerID'].notna() & (df['CustomerID'] > 0)\n",
    "seg_base = df[sale_mask & valid_customer_mask].copy()\n",
    "print('Segmentation base shape:', seg_base.shape)\n",
    "\n",
    "# Aggregations\n",
    "cust_agg = seg_base.groupby('CustomerID').agg(\n",
    "    TotalAmountSpent=('Revenue','sum'),\n",
    "    PurchaseFrequency=('InvoiceNo','nunique')\n",
    ")\n",
    "# Average Order Value\n",
    "cust_agg['AOV'] = cust_agg['TotalAmountSpent'] / cust_agg['PurchaseFrequency']\n",
    "\n",
    "# Preferred product (mode of Description)\n",
    "if 'Description' in seg_base.columns:\n",
    "    preferred = seg_base.groupby('CustomerID')['Description'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else 'Unknown')\n",
    "    cust_agg['PreferredProduct'] = preferred\n",
    "else:\n",
    "    cust_agg['PreferredProduct'] = 'Unknown'\n",
    "\n",
    "cust_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903b5b3a",
   "metadata": {},
   "source": [
    "## 13. Feature Scaling (StandardScaler)\n",
    "Scale numerical features to equalize influence in distance-based clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e44db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['TotalAmountSpent','PurchaseFrequency','AOV']\n",
    "# Clean up any inf/NaNs produced by division\n",
    "for f in features:\n",
    "    if cust_agg[f].isna().any():\n",
    "        cust_agg[f] = cust_agg[f].fillna(0)\n",
    "    cust_agg[f].replace([float('inf'), float('-inf')], 0, inplace=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_matrix = scaler.fit_transform(cust_agg[features])\n",
    "\n",
    "scaled_df = pd.DataFrame(scaled_matrix, columns=[f + '_scaled' for f in features], index=cust_agg.index)\n",
    "scaled_df['CustomerID'] = scaled_df.index.astype('int64')\n",
    "\n",
    "print('Scaled feature head:')\n",
    "display(scaled_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6c654",
   "metadata": {},
   "source": [
    "## 14. Choose Optimal k (Elbow & Silhouette)\n",
    "We evaluate k in 2..10 to select a balance of compactness and separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b46b7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "silhouette_scores = []\n",
    "X = scaled_df[[c for c in scaled_df.columns if c.endswith('_scaled')]].values\n",
    "\n",
    "k_values = range(2, 11)\n",
    "for k in k_values:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(X)\n",
    "    wcss.append(km.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X, labels))\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,4))\n",
    "axes[0].plot(list(k_values), wcss, marker='o'); axes[0].set_title('Elbow (WCSS)'); axes[0].set_xlabel('k'); axes[0].set_ylabel('WCSS')\n",
    "axes[1].plot(list(k_values), silhouette_scores, marker='o', color='green'); axes[1].set_title('Silhouette Score'); axes[1].set_xlabel('k'); axes[1].set_ylabel('Score')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Heuristic selection: choose k with high silhouette near the elbow\n",
    "optimal_k = int(k_values[int(np.argmax(silhouette_scores))])\n",
    "print('Selected k (silhouette argmax heuristic):', optimal_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ccf916",
   "metadata": {},
   "source": [
    "## 15. K-Means Training and Label Assignment\n",
    "Fit clustering model and attach segment labels to customer feature frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a617e849",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "labels = km_final.fit_predict(X)\n",
    "\n",
    "cust_agg['cluster_label'] = labels\n",
    "cust_agg['CustomerID'] = cust_agg.index.astype('int64')\n",
    "\n",
    "print('Cluster label counts:')\n",
    "print(cust_agg['cluster_label'].value_counts().sort_index())\n",
    "\n",
    "display(cust_agg.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb4673",
   "metadata": {},
   "source": [
    "## 16. Cluster Profiling and KPIs per Segment\n",
    "Summarize mean metrics and derive human-readable personas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052d8a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_summary = cust_agg.groupby('cluster_label').agg(\n",
    "    Customers=('CustomerID','count'),\n",
    "    MeanSpend=('TotalAmountSpent','mean'),\n",
    "    MeanFrequency=('PurchaseFrequency','mean'),\n",
    "    MeanAOV=('AOV','mean')\n",
    ").sort_index()\n",
    "\n",
    "# Preferred products per cluster (top 5 overall frequency among its members)\n",
    "if 'PreferredProduct' in cust_agg.columns:\n",
    "    pref_counts = cust_agg.groupby('cluster_label')['PreferredProduct'].value_counts()\n",
    "    top_products_per_cluster = {}\n",
    "    for c in cluster_summary.index:\n",
    "        top_products_per_cluster[c] = pref_counts[c].head(5)\n",
    "else:\n",
    "    top_products_per_cluster = {}\n",
    "\n",
    "# Persona logic relative to global means\n",
    "global_means = cluster_summary[['MeanSpend','MeanFrequency','MeanAOV']].mean()\n",
    "personas = {}\n",
    "for c, row in cluster_summary.iterrows():\n",
    "    spend_tier = 'High-Value' if row['MeanSpend'] > global_means['MeanSpend'] else 'Value-Conscious'\n",
    "    freq_tier = 'Frequent' if row['MeanFrequency'] > global_means['MeanFrequency'] else 'Occasional'\n",
    "    aov_tier = 'Premium AOV' if row['MeanAOV'] > global_means['MeanAOV'] else 'Standard AOV'\n",
    "    personas[c] = f\"{spend_tier} • {freq_tier} • {aov_tier}\"\n",
    "\n",
    "print('Cluster Summary:')\n",
    "display(cluster_summary)\n",
    "print('Personas:')\n",
    "for c, p in personas.items():\n",
    "    print(f\"Cluster {c}: {p}\")\n",
    "\n",
    "print('\\nTop products per cluster:')\n",
    "for c, series in top_products_per_cluster.items():\n",
    "    print(f\"Cluster {c} top products:\")\n",
    "    display(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f83f85",
   "metadata": {},
   "source": [
    "## 17. Visualizations: Trends and Segments\n",
    "Plot key trends and cluster separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e4d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revenue Trends by Date and Weekday\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure date sorted\n",
    "daily_rev = df.groupby(df['InvoiceDate'].dt.date)['Revenue'].sum().reset_index(name='Revenue')\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "ax.plot(daily_rev['InvoiceDate'], daily_rev['Revenue'], color='#1f77b4', linewidth=1)\n",
    "ax.set_title('Daily Revenue Trend')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Revenue')\n",
    "locator = mdates.AutoDateLocator(minticks=6, maxticks=12)\n",
    "ax.xaxis.set_major_locator(locator)\n",
    "ax.xaxis.set_major_formatter(mdates.ConciseDateFormatter(locator))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "a = df.groupby('Weekday', observed=True)['Revenue'].sum().reindex(['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'])\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "sns.barplot(x=a.index, y=a.values, palette='viridis', ax=ax)\n",
    "ax.set_title('Revenue by Weekday')\n",
    "ax.set_xlabel('Weekday')\n",
    "ax.set_ylabel('Revenue')\n",
    "ax.tick_params(axis='x', rotation=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806f90df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 Products by Revenue\n",
    "prod_rev = df.groupby('Description')['Revenue'].sum().sort_values(ascending=False).head(10)\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "sns.barplot(x=prod_rev.values, y=prod_rev.index, palette='magma', ax=ax)\n",
    "ax.set_title('Top 10 Products by Revenue')\n",
    "ax.set_xlabel('Revenue')\n",
    "ax.set_ylabel('Product')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Transaction Type Counts\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "tran_counts = df['Transaction_Type'].value_counts()\n",
    "sns.barplot(x=tran_counts.index, y=tran_counts.values, palette='Set2', ax=ax)\n",
    "ax.set_title('Transaction Type Counts')\n",
    "ax.set_xlabel('Type')\n",
    "ax.set_ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b322ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Segments: Scatter and Counts\n",
    "# Scatter: TotalAmountSpent vs PurchaseFrequency colored by cluster\n",
    "fig, ax = plt.subplots(figsize=(7,6))\n",
    "sns.scatterplot(\n",
    "    data=cust_agg,\n",
    "    x='TotalAmountSpent', y='PurchaseFrequency', hue='cluster_label',\n",
    "    palette='tab10', s=30, alpha=0.8, ax=ax\n",
    ")\n",
    "ax.set_title('Customer Segments: Spend vs Frequency')\n",
    "ax.set_xlabel('Total Amount Spent')\n",
    "ax.set_ylabel('Purchase Frequency')\n",
    "ax.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Counts per cluster\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "cl_counts = cust_agg['cluster_label'].value_counts().sort_index()\n",
    "sns.barplot(x=cl_counts.index.astype(str), y=cl_counts.values, palette='tab10', ax=ax)\n",
    "ax.set_title('Customers per Cluster')\n",
    "ax.set_xlabel('Cluster')\n",
    "ax.set_ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148f4b31",
   "metadata": {},
   "source": [
    "## 18. Persist Results (CSV + Plots)\n",
    "Save customer segmentation results and key figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf93da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure output directory exists (current working dir)\n",
    "out_dir = Path('.')\n",
    "\n",
    "# Export customer segmentation results\n",
    "cust_export_cols = ['CustomerID', 'TotalAmountSpent', 'PurchaseFrequency', 'AOV', 'PreferredProduct', 'cluster_label']\n",
    "export_df = cust_agg[cust_export_cols].copy()\n",
    "export_path = out_dir / 'customer_segmentation_results.csv'\n",
    "export_df.to_csv(export_path, index=False)\n",
    "print(f\"Saved customer segmentation to: {export_path.resolve()}\")\n",
    "\n",
    "# Save figures from earlier (elbow and silhouette if available in current session)\n",
    "try:\n",
    "    # Recompute quickly for saving, in case figures were closed\n",
    "    fig, ax = plt.subplots(figsize=(5,3))\n",
    "    ax.plot(range(2, len(wcss)+2), wcss, marker='o')\n",
    "    ax.set_title('Elbow Plot (WCSS)')\n",
    "    ax.set_xlabel('k')\n",
    "    ax.set_ylabel('WCSS')\n",
    "    plt.tight_layout()\n",
    "    elbow_path = out_dir / 'elbow.png'\n",
    "    fig.savefig(elbow_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {elbow_path.resolve()}\")\n",
    "except Exception as e:\n",
    "    print('Elbow figure not saved:', e)\n",
    "\n",
    "try:\n",
    "    fig, ax = plt.subplots(figsize=(5,3))\n",
    "    ax.plot(range(2, len(silhouette_scores)+2), silhouette_scores, marker='o')\n",
    "    ax.set_title('Silhouette Scores')\n",
    "    ax.set_xlabel('k')\n",
    "    ax.set_ylabel('Silhouette')\n",
    "    plt.tight_layout()\n",
    "    sil_path = out_dir / 'silhouette.png'\n",
    "    fig.savefig(sil_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {sil_path.resolve()}\")\n",
    "except Exception as e:\n",
    "    print('Silhouette figure not saved:', e)\n",
    "\n",
    "# Save cluster scatter plot\n",
    "try:\n",
    "    fig, ax = plt.subplots(figsize=(7,6))\n",
    "    sns.scatterplot(\n",
    "        data=cust_agg,\n",
    "        x='TotalAmountSpent', y='PurchaseFrequency', hue='cluster_label',\n",
    "        palette='tab10', s=30, alpha=0.8, ax=ax\n",
    "    )\n",
    "    ax.set_title('Customer Segments: Spend vs Frequency')\n",
    "    ax.set_xlabel('Total Amount Spent')\n",
    "    ax.set_ylabel('Purchase Frequency')\n",
    "    ax.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    seg_path = out_dir / 'segments.png'\n",
    "    fig.savefig(seg_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {seg_path.resolve()}\")\n",
    "except Exception as e:\n",
    "    print('Segments figure not saved:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1b4f28",
   "metadata": {},
   "source": [
    "## 19. Sanity Checks & Reproducibility\n",
    "Final assertions and reproducibility notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112b89d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assertions and basic data integrity checks\n",
    "# 1. No missing in critical segmentation columns\n",
    "critical_cols = ['TotalAmountSpent','PurchaseFrequency','AOV']\n",
    "for c in critical_cols:\n",
    "    assert cust_agg[c].isna().sum() == 0, f\"Unexpected NaNs in {c}\"\n",
    "print('Critical segmentation columns have no NaNs.')\n",
    "\n",
    "# 2. Cluster labels contiguous from 0..k-1\n",
    "labels = sorted(cust_agg['cluster_label'].unique())\n",
    "assert labels == list(range(len(labels))), 'Cluster labels not contiguous starting at 0.'\n",
    "print(f'Cluster labels contiguous: {labels}')\n",
    "\n",
    "# 3. Reasonable range checks\n",
    "assert cust_agg['TotalAmountSpent'].ge(0).all(), 'Negative spend detected.'\n",
    "assert cust_agg['PurchaseFrequency'].ge(1).all(), 'Purchase frequency <1 detected (should be at least 1).'\n",
    "print('Value range checks passed.')\n",
    "\n",
    "# 4. Personas coverage\n",
    "assert len(personas) == len(labels), 'Persona count mismatch with clusters.'\n",
    "print('Persona coverage matches cluster count.')\n",
    "\n",
    "# Reproducibility notes\n",
    "import random\n",
    "import numpy as np\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "print('Seed set for reproducibility (Python + NumPy). For scikit-learn models, random_state already applied.')\n",
    "\n",
    "print('\\nAll sanity checks passed. Notebook ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd1ee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personas JSON Export\n",
    "import json\n",
    "personas_path = 'personas.json'\n",
    "try:\n",
    "    with open(personas_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(personas, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"Saved personas to {personas_path}\")\n",
    "except Exception as e:\n",
    "    print('Failed to save personas JSON:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea282f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Capture (Freeze Dependencies)\n",
    "# Run this cell AFTER installing required packages to produce a requirements_generated.txt\n",
    "import subprocess, sys, pathlib\n",
    "req_out = pathlib.Path('requirements_generated.txt')\n",
    "try:\n",
    "    result = subprocess.run([sys.executable, '-m', 'pip', 'freeze'], capture_output=True, text=True, check=True)\n",
    "    req_out.write_text(result.stdout)\n",
    "    print(f\"Captured environment to {req_out.resolve()} (lines: {len(result.stdout.strip().splitlines())})\")\n",
    "except Exception as e:\n",
    "    print('Failed to capture environment:', e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
